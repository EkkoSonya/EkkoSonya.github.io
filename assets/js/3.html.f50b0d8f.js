"use strict";(self.webpackChunklearn_data=self.webpackChunklearn_data||[]).push([[9155],{83671:(n,a)=>{a.A=(n,a)=>{const s=n.__vccOpts||n;for(const[n,e]of a)s[n]=e;return s}},41767:(n,a,s)=>{s.r(a),s.d(a,{comp:()=>m,data:()=>g});var e=s(7847);const t=s.p+"assets/img/6.43c43951.png",o=s.p+"assets/img/7.fa22c29f.png",p=s.p+"assets/img/8.e22867fc.png",c=s.p+"assets/img/9.5c235627.png",i=s.p+"assets/img/10.b8dbfc04.png",l=s.p+"assets/img/11.760ba2f0.png",r=(0,e.Fv)('<h2 id="客户端工作机制2" tabindex="-1"><a class="header-anchor" href="#客户端工作机制2"><span>客户端工作机制2</span></a></h2><h3 id="生产者消息缓存机制" tabindex="-1"><a class="header-anchor" href="#生产者消息缓存机制"><span>生产者消息缓存机制</span></a></h3><p>目前已经分析了消费者组、消息发送和接受时的序列化和反序列化，以及具体消息发送是到哪个partition和consumer接受哪个partition的消息</p><p>接下来就是如何具体发送消息了</p><p>​Kafka生产者为了避免高并发请求对服务端造成过大压力，每次发消息时并不是一条一条发往服务端，而是增加了一个高速缓存，将消息集中到缓存后，批量进行发送。这种缓存机制也是高并发处理时非常常用的一种机制</p><p>Kafka的消息缓存机制涉及到KafkaProducer中的两个关键组件： <code>accumulator</code> 和 <code>sender</code></p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token comment">//1.记录累加器</span>\n<span class="token keyword">int</span> batchSize <span class="token operator">=</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span><span class="token function">getInt</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n<span class="token keyword">this</span><span class="token punctuation">.</span>accumulator <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">RecordAccumulator</span><span class="token punctuation">(</span>logContext<span class="token punctuation">,</span>batchSize<span class="token punctuation">,</span><span class="token keyword">this</span><span class="token punctuation">.</span>compressionType<span class="token punctuation">,</span><span class="token function">lingerMs</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">,</span>retryBackoffMs<span class="token punctuation">,</span>deliveryTimeoutMs<span class="token punctuation">,</span> partitionerConfig<span class="token punctuation">,</span>metrics<span class="token punctuation">,</span><span class="token constant">PRODUCER_METRIC_GROUP_NAME</span><span class="token punctuation">,</span>time<span class="token punctuation">,</span>apiVersions<span class="token punctuation">,</span>transactionManager<span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">BufferPool</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>totalMemorySize<span class="token punctuation">,</span> batchSize<span class="token punctuation">,</span> metrics<span class="token punctuation">,</span> time<span class="token punctuation">,</span> <span class="token constant">PRODUCER_METRIC_GROUP_NAME</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n<span class="token comment">//2. 数据发送线程</span>\n<span class="token keyword">this</span><span class="token punctuation">.</span>sender <span class="token operator">=</span> <span class="token function">newSender</span><span class="token punctuation">(</span>logContext<span class="token punctuation">,</span> kafkaClient<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>metadata<span class="token punctuation">)</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="'+t+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><h4 id="recordaccumulator" tabindex="-1"><a class="header-anchor" href="#recordaccumulator"><span><code>RecordAccumulator</code></span></a></h4><p>RecordAccumulator，就是Kafka生产者的消息累加器</p><p>KafkaProducer要发送的消息都会在<code>ReocrdAccumulator</code>中缓存起来，然后再分批发送给kafka broker</p><p>在我们调用 Producer 的 <code>send</code> 方法时，最终就会调用将我们的 <code>Record</code> 存到累加器里</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">RecordAccumulator<span class="token punctuation">.</span>RecordAppendResult</span> result <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>accumulator<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> partition<span class="token punctuation">,</span> timestamp<span class="token punctuation">,</span> serializedKey<span class="token punctuation">,</span> serializedValue<span class="token punctuation">,</span> headers<span class="token punctuation">,</span> appendCallbacks<span class="token punctuation">,</span> remainingWaitMs<span class="token punctuation">,</span> abortOnNewBatch<span class="token punctuation">,</span> nowMs<span class="token punctuation">,</span> cluster<span class="token punctuation">)</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>成功存完之后，再会去尝试唤醒 sender 来实现消息发送</p><p>在<code>RecordAccumulator</code>中，其每一个Deque双端队列对应的是具体一个Topic下的一个Partition</p><p>这些Dequeue队列基本上是和Kafka服务端的Topic下的Partition对应的</p><p>每个Dequeue里会放入若干个ProducerBatch数据</p><p>KafkaProducer每次发送的消息，都会根据key分配到对应的Deque队列中, 然后每个消息都会保存在这些队列中的某一个ProducerBatch中</p><p>而消息分发的规则，就是由上面的Partitioner组件完成的, 来选择把这个消息发到哪个Partition，即内部是存到哪个 Dequeue 里面</p><h5 id="主要参数-buffer-memory-config-batch-size-config" tabindex="-1"><a class="header-anchor" href="#主要参数-buffer-memory-config-batch-size-config"><span>主要参数 <code>BUFFER_MEMORY_CONFIG</code> + <code>BATCH_SIZE_CONFIG</code></span></a></h5><p>对于 <code>RecordAccumulator</code> 主要涉及两个参数</p><ul><li><code>BUFFER_MEMORY_CONFIG</code>：就是这个累加器缓冲区的总大小</li><li><code>BATCH_SIZE_CONFIG</code>：缓冲区每一个batch的大小，作为发送的最小单位 (默认 16K)</li></ul><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token comment">//RecordAccumulator缓冲区大小</span>\n<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BUFFER_MEMORY_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;buffer.memory&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BUFFER_MEMORY_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The total bytes of memory the producer can use to buffer records waiting to be sent to the server.&quot;</span> <span class="token operator">+</span> \n<span class="token string">&quot;If records are sent faster than they can be delivered to the server the producer will block for &lt;code&gt;max.block.ms&lt;/code&gt; after which it will throw an exception.&quot;</span> <span class="token operator">+</span> \n<span class="token string">&quot;&lt;p&gt;This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering.&quot;</span> <span class="token operator">+</span> \n<span class="token string">&quot;Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.&quot;</span><span class="token punctuation">;</span>\n\n\n<span class="token comment">//缓冲区每一个batch的大小</span>\n<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BATCH_SIZE_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;batch.size&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BATCH_SIZE_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;This helps performance on both the client and the server. This configuration controls the default batch size in bytes.&quot;</span> <span class="token operator">+</span> \n<span class="token string">&quot;&lt;p&gt;No attempt will be made to batch records larger than this size.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;p&gt;Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.&lt;p&gt;&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable batching entirely).&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;A very large batch size may use memory a bit more wastefully as we will always allocate a buffer of the specified batch size in anticipation of additional records.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;p&gt;Note: This setting gives the upper bound of the batch size to be sent.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;If we have fewer than this many bytes accumulated for this partition, we will &#39;linger&#39; for the &lt;code&gt;linger.ms&lt;/code&gt; time waiting for more records to show up.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;This &lt;code&gt;linger.ms&lt;/code&gt; setting defaults to 0, which means we&#39;ll immediately send out a record even the accumulated batch size is under this &lt;code&gt;batch.size&lt;/code&gt; setting.&quot;</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="sender" tabindex="-1"><a class="header-anchor" href="#sender"><span><code>Sender</code></span></a></h4><figure><img src="'+o+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>sender就是KafkaProducer中用来发送消息的一个单独的线程</p><p>从这里可以看到，每个KafkaProducer对象都对应一个sender线程</p><p>他会负责将RecordAccumulator中的消息发送给Kafka</p><p>Sender也并不是一次就把RecordAccumulator中缓存的所有消息都发送出去，而是每次只拿一部分消息</p><p>他只获取<code>RecordAccumulator</code>中缓存内容达到<code>BATCH_SIZE_CONFIG</code>大小的<code>ProducerBatch</code>消息</p><p>当然，如果消息比较少，<code>ProducerBatch</code>中的消息大小长期达不到<code>BATCH_SIZE_CONFIG</code>的话，Sender也不会一直等待，最多等待<code>LINGER_MS_CONFIG</code>时长，然后就会将<code>ProducerBatch</code>中的消息读取出来</p><p><code>LINGER_MS_CONFIG</code>默认值是0，这意味着 Sender 默认是不会等待的</p><p>​然后，Sender对读取出来的消息，会以Broker为key，缓存到一个对应的队列当中 (<code>InflightBatches</code>)</p><p>这些队列当中的消息就称为<code>InflightRequest</code></p><p>接下来这些<code>Inflight</code>就会一一发往Kafka对应的Broker中，直到收到Broker的响应，才会从队列中移除</p><p>这些队列也并不会无限缓存，最多缓存<code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code>(默认值为5)个请求</p><p>即每次 累加器唤醒sender时，它就会根据对应的设置<code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code> 默认从累加器中最多拉取5条消息放到 <code>InflightBatches</code>中，然后去发给kafka的Broker</p><p>然后发送过去不会立刻又发，会等待 Broker 返回响应确认消息已经成功发送了 (ack应答)</p><blockquote><p>生产者缓存机制的主要目的是将消息打包，减少网络IO频率。所以，在Sender的InflightRequest队列中，消息也不是一条一条发送给Broker的，而是一批消息一起往Broker发送。而这就意味着这一批消息是没有固定的先后顺序的。</p></blockquote><h5 id="sender-什么时候去-deque-拉取消息" tabindex="-1"><a class="header-anchor" href="#sender-什么时候去-deque-拉取消息"><span>sender 什么时候去 Deque 拉取消息</span></a></h5><p>当一个<code>Dequeue</code>中消息容量超过了设定的 <code>BATCH_SIZE_CONFIG</code>，那么就会唤醒sender，叫他来收信息去发送</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token comment">//org.apache.kafka.clients.producer.KafkaProducer#doSend</span>\n<span class="token keyword">if</span> <span class="token punctuation">(</span>result<span class="token punctuation">.</span>batchIsFull <span class="token operator">||</span> result<span class="token punctuation">.</span>newBatchCreated<span class="token punctuation">)</span> <span class="token punctuation">{</span>\n  log<span class="token punctuation">.</span><span class="token function">trace</span><span class="token punctuation">(</span><span class="token string">&quot;Waking up the sender since topic {} partition {} is either full or getting a new batch&quot;</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> appendCallbacks<span class="token punctuation">.</span><span class="token function">getPartition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n  <span class="token keyword">this</span><span class="token punctuation">.</span>sender<span class="token punctuation">.</span><span class="token function">wakeup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n<span class="token punctuation">}</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>或者等待时间超过了 <code>LINGER_MS_CONFIG</code>，那么 sender 也会自动去拉取一批消息</p><h5 id="主要参数-linger-ms-config-max-in-flight-requests-per-connection" tabindex="-1"><a class="header-anchor" href="#主要参数-linger-ms-config-max-in-flight-requests-per-connection"><span>主要参数 <code>LINGER_MS_CONFIG</code> + <code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code></span></a></h5><ul><li><code>LINGER_MS_CONFIG</code>：默认0，意思默认情况下不会等你装满，而是一直会尝试拉取消息去发送</li><li><code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code>：默认是5，</li></ul><p>这两个被标记 <code>@Deprecated</code>, 为了确保幂等性，<code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</code> 必须小于5</p><p>Kafka 社区希望用户 只关注“开启幂等性”这一高层意图，而不必去微调底层的 max.in.flight 参数</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">LINGER_MS_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;linger.ms&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">LINGER_MS_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The producer groups together any records that arrive in between request transmissions into a single batched request. Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding a small amount of artificial delay&amp;mdash;that is, rather than immediately sending out a record, the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together. This can be thought of as analogous to Nagle&#39;s algorithm in TCP. This setting gives the upper bound on the delay for batching: once we get &lt;code&gt;batch.size&lt;/code&gt; worth of records for a partition it will be sent immediately regardless of this setting, however if we have fewer than this many bytes accumulated for this partition we will &#39;linger&#39; for the specified time waiting for more records to show up. This setting defaults to 0 (i.e. no delay). Setting &lt;code&gt;linger.ms=5&lt;/code&gt;, for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency to records sent in the absence of load.&quot;</span><span class="token punctuation">;</span>\n\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token constant">MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION_FOR_IDEMPOTENCE</span> <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>\n<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</span> <span class="token operator">=</span> <span class="token string">&quot;max.in.flight.requests.per.connection&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The maximum number of unacknowledged requests the client will send on a single connection before blocking.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;Note that if this configuration is set to be greater than 1 and &lt;code&gt;enable.idempotence&lt;/code&gt; is set to false, there is a risk of message reordering after a failed send due to retries (i.e., if retries are enabled);&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;if retries are disabled or if &lt;code&gt;enable.idempotence&lt;/code&gt; is set to true, ordering will be preserved.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;Additionally, enabling idempotence requires the value of this configuration to be less than or equal to 5.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled. &quot;</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后，Sender会通过其中的一个Selector组件完成与Kafka的IO请求，并接收Kafka的响应, 成功拿到ACK响应后，才会把对应的消息移除掉</p><p>Kafka的生产者缓存机制是Kafka面对海量消息时非常重要的优化机制</p><p>合理优化这些参数，对于Kafka集群性能提升是非常重要的</p><p>比如如果你的消息体比较大，那么应该考虑加大batch.size，尽量提升batch的缓存效率</p><p>而如果Producer要发送的消息确实非常多，那么就需要考虑加大total.memory参数，尽量避免缓存不够造成的阻塞</p><p>如果发现生产者发送消息比较慢，那么可以考虑提升<code>max.in.flight.requests.per.connection</code>参数，这样能加大消息发送的吞吐量</p><h3 id="发送应答机制" tabindex="-1"><a class="header-anchor" href="#发送应答机制"><span>发送应答机制</span></a></h3><p>在Producer将消息发送到Broker后，要怎么确定消息是不是成功发到Broker上了呢？</p><p>​这是在开发过程中比较重要的一个机制，也是面试过程中最喜欢问的一个机制</p><p>这里涉及到的，就是在Producer端一个不太起眼的属性<code>ACKS_CONFIG</code></p><p>这说明判断消息是否成功接收，这个设置是由我们客户端决定的，然后进行处理，而不是由服务端kafka决定的</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">ACKS_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;acks&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">ACKS_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The number of acknowledgments the producer requires the leader to have received before considering a request complete.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;This controls the  durability of records that are sent. The following settings are allowed:&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;ul&gt;&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt; If set to zero then the producer will not wait for any acknowledgment from the server at all.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;The record will be immediately added to the socket buffer and considered sent.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;No guarantee can be made that the server has received the record in this case,&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;and the &lt;code&gt;retries&lt;/code&gt; configuration will not take effect (as the client won&#39;t generally know of any failures).&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;The offset given back for each record will always be set to &lt;code&gt;-1&lt;/code&gt;.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt; This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt; This means the leader will wait for the full set of in-sync replicas to acknowledge the record.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;This is the strongest available guarantee. This is equivalent to the acks=-1 setting.&lt;/ul&gt;&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;p&gt;Note that enabling idempotence requires this config value to be &#39;all&#39;.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled.&quot;</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>​官方给出的这段解释，同样比任何外部的资料都要准确详细了</p><p>如果你理解了Topic的分区模型，这个属性就非常容易理解了</p><p>这个属性更大的作用在于保证消息的安全性，尤其在<code>replica-factor</code>备份因子比较大的Topic中，尤为重要</p><ul><li><code>acks=0</code>，生产者不关心Broker端有没有将消息写入到Partition，只发送消息就不管了。吞吐量是最高的，但是数据安全性是最低的</li><li><code>acks=1</code>，则是一种相对中和的策略。Leader Partition在完成自己的消息写入后，就向生产者返回结果</li><li><code>acks=all or -1</code>，生产者需要等Broker端的所有Partiton(Leader Partition以及其对应的Follower Partition)都写完了才能得到返回结果，这样数据是最安全的，但是每次发消息需要等待更长的时间，吞吐量是最低的。</li></ul><blockquote><p>在生产环境中，acks=0可靠性太差，很少使用。acks=1，一般用于传输日志等，允许个别数据丢失的场景。使用范围最广。acks=-1，一般用于传输敏感数据，比如与钱相关的数据</p></blockquote><h4 id="ack-1-or-1" tabindex="-1"><a class="header-anchor" href="#ack-1-or-1"><span><code>ack=1 or -1</code></span></a></h4><p>​如果ack设置为all或者-1，Kafka也并不是强制要求所有Partition都写入数据后才响应</p><p>实际上默认Broker只要成功同步一个Follower，就会向服务端返回响应 (建议设置为副本数的一半)</p><p>在Kafka的Broker服务端会有一个配置参数<code>min.insync.replicas</code>，控制Leader Partition在完成多少个Partition的消息写入后，往Producer返回响应</p><p>这个参数可以在broker.conf文件中进行配置</p><div class="language-conf line-numbers-mode" data-ext="conf" data-title="conf"><pre class="language-conf"><code>min.insync.replicas\nWhen a producer sets acks to &quot;all&quot; (or &quot;-1&quot;), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).\nWhen used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of &quot;all&quot;. This will ensure that the producer raises an exception if a majority of replicas do not receive a write.\n\nType: int\nDefault: 1\nValid Values: [1,...]\nImportance: high\nUpdate Mode: cluster-wide\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>关于消息应答机制，最后强调一点：acks设置成all或者-1，能够有效提高消息的安全性。但是从消息安全性方面考虑，应答机制只是保证Broker可以给Producer一个比较靠谱的响应，但并不代表就保证了消息不丢失</p><p>即设置了 ACK 机制目的只是来让服务端知道这个消息是传递成功了还是失败了，然后根据后续结果来自己决定该怎么处理，比如消息丢失的情况</p><p><code>Producer</code>拿到响应后如何进行后续处理，Kafka是不参与的。</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token class-name">RecordMetadata</span> recordMetadata <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>通过ACKs机制，可以保证拿到这个 <code>RecordMetadata</code> 这个响应结果是什么状态，而之后怎么处理服务端是不管的</p><h4 id="幂等性要求" tabindex="-1"><a class="header-anchor" href="#幂等性要求"><span>幂等性要求</span></a></h4><p>acks机制的配置不光影响到客户端什么时候收到相应，同时在服务端还影响到消息幂等性机制(idempotence)</p><p>(幂等性)当我消息发过去了，成功了服务端就应该只记录一条消息，消费者也只有一条信息</p><p>网络是不靠谱的，如果生产者发送了一条信息，成功传给了broker，对应服务端也保存了，但是在发送 ack 请求的时候丢了，那么生产者等不到消息就默认发送失败了，那又会重新发送，这就导致本来存过一次的消息又存了一遍，这就需要确保幂等性</p><p>那么服务端就需要处理这种特殊情况，从而可以保证消息的幂等性</p><h3 id="生产者消息幂等性" tabindex="-1"><a class="header-anchor" href="#生产者消息幂等性"><span>生产者消息幂等性</span></a></h3><p>源码中对于acks属性的说明，会看到另外一个单词，idempotence 这个单词的意思就是幂等性</p><h4 id="幂等性问题" tabindex="-1"><a class="header-anchor" href="#幂等性问题"><span>幂等性问题</span></a></h4><p>之前分析过，当Producer的acks设置成1或-1时，Producer每次发送消息都是需要获取Broker端返回的RecordMetadata的。这个过程中就需要两次跨网络请求</p><figure><img src="'+p+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>如果要保证消息安全，那么对于每个消息，这两次网络请求就必须要求是幂等的</p><p>但是，网络是不靠谱的，在高并发场景下，往往没办法保证这两个请求是幂等的</p><p>Producer发送消息的过程中，如果第一步请求成功了，但是第二步却没有返回，这时，Producer就会认为消息发送失败了，那么Producer必然会发起重试</p><p>重试次数由参数<code>ProducerConfig.RETRIES_CONFIG</code>，默认值是<code>Integer.MAX</code></p><p>这时问题就来了, Producer会重复发送多条消息到Broker中, Kafka如何保证无论Producer向Broker发送多少次重复的数据，Broker端都只保留一条消息，而不会重复保存多条消息呢？</p><p>这就是Kafka消息生产者的幂等性问题</p><h5 id="分布式数据传递三个数据语义" tabindex="-1"><a class="header-anchor" href="#分布式数据传递三个数据语义"><span>分布式数据传递三个数据语义</span></a></h5><ul><li><code>at-least-once</code>: 至少一次</li><li><code>at-most-once</code>: 最多一次</li><li><code>exactly-once</code>: 精确一次</li></ul><p>比如，你往银行存100块钱，这时银行往往需要将存钱动作转化成一个消息，发到MQ，然后通过MQ通知另外的系统去完成修改你的账户余额以及其他一些其他的业务动作</p><p>而这个MQ消息的安全性，往往是需要分层次来设计的</p><p>首先，你要保证存钱的消息能够一定发送到MQ, 如果一次发送失败了，那就重试几次，只到成功为止, 这就是 <strong>at-least-once</strong> 至少一次, 如果保证不了这个语义，那么你肯定不会接受</p><p>然后，你往银行存100块，不管这个消息你发送了多少次，银行最多只能记录一次，也就是100块存款，可以少，但决不能多, 这就是 <strong>at-most-once</strong> 最多一次</p><p>最后，这个业务动作要让双方都满意，就必须保证存钱这个消息正正好好被记录一次，不多也不少, 这就是 <strong>Exactly-once</strong> 语义</p><p>所以，通常意义上，<strong>at-least-once</strong> 可以保证数据不丢失，但是不能保证数据不重复</p><p>而 <strong>at-most-once</strong> 保证数据不重复，但是又不能保证数据不丢失</p><p>这两种语义虽然都有缺陷，但是实现起来相对来说比较简单。但是对一些敏感的业务数据，往往要求数据即不重复也不丢失，这就需要支持 <strong>Exactly-once</strong> 语义, 而要支持Exactly-once语义，需要有非常精密的设计。</p><p>​回到Producer发消息给Broker这个场景</p><p>如果要保证 at-most-once 语义，可以将ack级别设置为0即可，此时，是不存在幂等性问题的</p><p>如果要保证at-least-once语义，就需要将ack级别设置为1或者-1，这样就能保证Leader Partition中的消息至少是写成功了一次的，但是不保证只写了一次</p><p>如果要支持Exactly-once语义怎么办呢？这就需要使用到idempotence幂等性属性了</p><h4 id="kafka-幂等性实现" tabindex="-1"><a class="header-anchor" href="#kafka-幂等性实现"><span>kafka 幂等性实现</span></a></h4><figure><img src="'+c+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>​Kafka为了保证消息发送的Exactly-once语义，增加了几个概念：</p><ul><li><p><code>PID</code>：每个新的Producer在初始化的过程中就会被分配一个唯一的PID。这个PID对用户是不可见的</p></li><li><p><code>Sequence Numer</code>: 对于每个PID，这个Producer针对Partition会维护一个sequenceNumber。这是一个从0开始单调递增的数字。当Producer要往同一个Partition发送消息时，这个Sequence Number就会加1。然后会随着消息一起发往Broker</p></li><li><p><code>SN</code>: Broker端则会针对每个<code>&lt;PID,Partition&gt;</code>维护一个序列号(SN)，只有当对应的<code>Sequence Number = SN+1</code>时，Broker才会接收消息，同时将SN更新为SN+1。否则，<code>SequenceNumber</code>过小就认为消息已经写入了，不需要再重复写入。而如果<code>SequenceNumber</code>过大，就会认为中间可能有数据丢失了。对生产者就会抛出一个<code>OutOfOrderSequenceException</code></p></li></ul><p>​这样，Kafka在打开idempotence幂等性控制后，在Broker端就会保证每条消息在一次发送过程中，Broker端最多只会刚刚好持久化一条。这样就能保证at-most-once语义。再加上之前分析的将生产者的acks参数设置成1或-1，保证at-least-once语义，这样就整体上保证了Exactaly-once语义</p><h4 id="幂等性作用范围" tabindex="-1"><a class="header-anchor" href="#幂等性作用范围"><span>幂等性作用范围</span></a></h4><p>首先，它只能保证单分区上的幂等性，即⼀个幂等性Producer能够保证某个主题的⼀个分区上不出现重复消息，它无法实现多个分区的幂等性</p><p>其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p><p>这里的会话，可以理解为Producer进程的⼀次运行，当你重启了Producer进程之后，这种幂等性保证就丧失了</p><h4 id="kafka-幂等性配置" tabindex="-1"><a class="header-anchor" href="#kafka-幂等性配置"><span>kafka 幂等性配置</span></a></h4><p>Kafka围绕生产者幂等性问题，其实是做了一整套设计的</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">ENABLE_IDEMPOTENCE_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;enable.idempotence&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">ENABLE_IDEMPOTENCE_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;When set to &#39;true&#39;, the producer will ensure that exactly one copy of each message is written in the stream.&quot;</span><span class="token operator">+</span> \n<span class="token string">&quot;If &#39;false&#39;, producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;Note that enabling idempotence&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;requires &lt;code&gt;max.in.flight.requests.per.connection&lt;/code&gt; to be less than or equal to 5 (with message ordering preserved for any allowable value),&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;&lt;code&gt;retries&lt;/code&gt; to be greater than 0, and &lt;code&gt;acks&lt;/code&gt; must be &#39;all&#39;. &lt;p&gt;&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;Idempotence is enabled by default if no conflicting configurations are set.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled.&quot;</span><span class="token operator">+</span>\n<span class="token string">&quot;If idempotence is explicitly enabled and conflicting configurations are set, a &lt;code&gt;ConfigException&lt;/code&gt; is thrown.&quot;</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在当前 kafka 的幂等性是默认开启的</p><p>要保证幂等性可以实现</p><ul><li><code>max.in.flight.requests.per.connection</code> 必须小于5</li><li><code>retries</code> 必须大于0，存在重试</li><li><code>acks</code> 必须设置为 <code>all</code></li></ul><h3 id="生产者数据压缩机制" tabindex="-1"><a class="header-anchor" href="#生产者数据压缩机制"><span>生产者数据压缩机制</span></a></h3><p>当生产者往Broker发送消息时，还会对每个消息进行压缩，从而降低Producer到Broker的网络数据传输压力，同时也降低了Broker的数据存储压力</p><p>具体涉及到ProducerConfig中的 <code>COMPRESSION_TYPE_CONFIG</code> 配置项</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">COMPRESSION_TYPE_CONFIG</span> <span class="token operator">=</span> <span class="token string">&quot;compression.type&quot;</span><span class="token punctuation">;</span>\n<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">COMPRESSION_TYPE_DOC</span> <span class="token operator">=</span> <span class="token string">&quot;The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid  values are &lt;code&gt;none&lt;/code&gt;, &lt;code&gt;gzip&lt;/code&gt;, &lt;code&gt;snappy&lt;/code&gt;, &lt;code&gt;lz4&lt;/code&gt;, or &lt;code&gt;zstd&lt;/code&gt;. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).&quot;</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>从介绍中可以看到，Kafka的生产者支持四种压缩算法。这几种压缩算法中，zstd算法具有最高的数据压缩比，但是吞吐量不高。lz4在吞吐量方面的优势比较明显。在实际使用时，可以根据业务情况选择合适的压缩算法。但是要注意下，压缩消息必然增加CPU的消耗，如果CPU资源紧张，就不要压缩了</p><p>关于数据压缩机制，在Broker端的broker.conf文件中，也是可以配置压缩算法的。正常情况下，Broker从Producer端接收到消息后不会对其进行任何修改，但是如果Broker端和Producer端指定了不同的压缩算法，就会产生很多异常的表现</p><div class="language-conf line-numbers-mode" data-ext="conf" data-title="conf"><pre class="language-conf"><code>compression.type\nSpecify the final compression type for a given topic. This configuration accepts the standard compression codecs (&#39;gzip&#39;, &#39;snappy&#39;, &#39;lz4&#39;, &#39;zstd&#39;). It additionally accepts &#39;uncompressed&#39; which is equivalent to no compression; and &#39;producer&#39; which means retain the original compression codec set by the producer.\n\nType: string\nDefault: producer\nValid Values: [uncompressed, zstd, lz4, snappy, gzip, producer]\nServer Default Property: compression.type\nImportance: medium\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果开启了消息压缩，那么在消费者端自然是要进行解压缩的</p><p>在Kafka中，消息从Producer到Broker再到Consumer会一直携带消息的压缩方式，这样当Consumer读取到消息集合时，自然就知道了这些消息使用的是哪种压缩算法，也就可以自己进行解压了</p><p>但是这时要注意的是应用中使用的Kafka客户端版本和Kafka服务端版本是否匹配。</p><h3 id="生产者消息事务" tabindex="-1"><a class="header-anchor" href="#生产者消息事务"><span>生产者消息事务</span></a></h3><p>​接下来，通过生产者消息幂等性问题，能够解决单生产者消息写入单分区的的幂等性问题</p><p>但是，如果是要写入多个分区呢？</p><p>比如生产者一次发送多条消息，然后给不同的消息指定不同的key</p><p>这批消息就有可能写入多个Partition，而这些Partition是分布在不同Broker上的, 这意味着，Producer需要对多个Broker同时保证消息的幂等性</p><figure><img src="'+i+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>​这时候，通过上面的生产者消息幂等性机制就无法保证所有消息的幂等了。这时候就需要有一个事务机制，保证这一批消息最好同时成功的保持幂等性。或者这一批消息同时失败，这样生产者就可以开始进行整体重试，消息不至于重复</p><p>即目的：保证发送多条消息这个操作也是原子性</p><h4 id="事务api" tabindex="-1"><a class="header-anchor" href="#事务api"><span>事务API</span></a></h4><p>对这个问题， Kafka就引入了消息事务机制。这涉及到Producer中的几个API</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token comment">// 1 初始化事务</span>\n<span class="token keyword">void</span> <span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n<span class="token comment">// 2 开启事务</span>\n<span class="token keyword">void</span> <span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>\n<span class="token comment">// 3 提交事务</span>\n<span class="token keyword">void</span> <span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>\n<span class="token comment">// 4 放弃事务（类似于回滚事务的操作）</span>\n<span class="token keyword">void</span> <span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="示例" tabindex="-1"><a class="header-anchor" href="#示例"><span>示例</span></a></h4><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TransactionErrorDemo</span> <span class="token punctuation">{</span>\n  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BOOTSTRAP_SERVERS</span> <span class="token operator">=</span> <span class="token string">&quot;worker1:9092,worker2:9092,worker3:9092&quot;</span><span class="token punctuation">;</span>\n  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">TOPIC</span> <span class="token operator">=</span> <span class="token string">&quot;disTopic&quot;</span><span class="token punctuation">;</span>\n\n  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ExecutionException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>\n      <span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 此处配置的是kafka的端口</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">BOOTSTRAP_SERVERS</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 事务ID</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">TRANSACTIONAL_ID_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;111&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 配置key的序列化类</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 配置value的序列化类</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n\n      <span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>\n      producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\n          <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;MyProducer&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>\n          <span class="token comment">//异步发送。</span>\n          producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">;</span>\n          <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">{</span>\n              <span class="token comment">//第三条消息放弃事务之后，整个这一批消息都回退了。</span>\n              <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;error&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n              producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n          <span class="token punctuation">}</span>\n      <span class="token punctuation">}</span>\n      <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;message sended&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token keyword">try</span> <span class="token punctuation">{</span>\n          <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>\n          e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token punctuation">}</span>\n    <span class="token comment">//producer.commitTransaction();</span>\n      producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n  <span class="token punctuation">}</span>\n<span class="token punctuation">}</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以先启动一个订阅了disTopic这个Topic的消费者，然后启动这个生产者，进行试验。在这个试验中，发送到第3条消息时，主动放弃事务，此时之前的消息也会一起回滚</p><h4 id="分析" tabindex="-1"><a class="header-anchor" href="#分析"><span>分析</span></a></h4><p>实际上，Kafka的事务消息还会做两件事情：</p><p>1、一个TransactionId只会对应一个PID</p><p>如果当前一个Producer的事务没有提交，而另一个新的Producer保持相同的TransactionId，这时旧的生产者会立即失效，无法继续发送消息</p><p>2、跨会话事务对齐</p><p>​如果某个Producer实例异常宕机了，事务没有被正常提交。那么新的TransactionId相同的Producer实例会对旧的事务进行补齐。保证旧事务要么提交，要么终止。这样新的Producer实例就可以以一个正常的状态开始工作</p>',151),u={href:"https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP98ExactlyOnceDeliveryandTransactionalMessaging-AnExampleApplication",target:"_blank",rel:"noopener noreferrer"},d=(0,e.Fv)('<p>所以，如果一个Producer需要发送多条消息，通常比较安全的发送方式是这样的：</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TransactionProducer</span> <span class="token punctuation">{</span>\n  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">BOOTSTRAP_SERVERS</span> <span class="token operator">=</span> <span class="token string">&quot;worker1:9092,worker2:9092,worker3:9092&quot;</span><span class="token punctuation">;</span>\n  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token constant">TOPIC</span> <span class="token operator">=</span> <span class="token string">&quot;disTopic&quot;</span><span class="token punctuation">;</span>\n  <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ExecutionException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>\n      <span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 此处配置的是kafka的端口</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">BOOTSTRAP_SERVERS</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 事务ID。</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">TRANSACTIONAL_ID_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;111&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 配置key的序列化类</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token comment">// 配置value的序列化类</span>\n      props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span><span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n\n      <span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>\n      producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token keyword">try</span><span class="token punctuation">{</span>\n          <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\n              <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;MyProducer&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>\n              <span class="token comment">//异步发送。</span>\n              producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">;</span>\n          <span class="token punctuation">}</span>\n          producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> e<span class="token punctuation">)</span><span class="token punctuation">{</span>\n          producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token punctuation">}</span><span class="token keyword">finally</span> <span class="token punctuation">{</span>\n          producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\n      <span class="token punctuation">}</span>\n  <span class="token punctuation">}</span>\n<span class="token punctuation">}</span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中对于事务ID这个参数，可以任意起名，但是建议包含一定的业务唯一性。</p><p>​生产者的事务消息机制保证了Producer发送消息的安全性，但是，他并不保证已经提交的消息就一定能被所有消费者消费</p><h3 id="流程总结" tabindex="-1"><a class="header-anchor" href="#流程总结"><span>流程总结</span></a></h3><p>对于这些属性，你并不需要煞有介事的强行去记忆，随时可以根据ProducerConfig和ConsumerConfig以及他们的父类CommonClientConfig去理解，大部分的属性都配有非常简明扼要的解释。</p><p>但是，一定需要尝试自己建立一个消息流转模型，理解其中比较重要的过程。然后重点从高可用，高并发的角度去理解Kafka客户端的设计，最后再尝试往其中填充具体的参数。</p><figure><img src="'+l+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure>',8),k={},m=(0,s(83671).A)(k,[["render",function(n,a){const s=(0,e.g2)("ExternalLinkIcon");return(0,e.uX)(),(0,e.CE)("div",null,[r,(0,e.Lk)("blockquote",null,[(0,e.Lk)("p",null,[(0,e.eW)("如果你对消息事务的实现机制比较感兴趣，可以自行参看下Apache下的这篇文章： "),(0,e.Lk)("a",u,[(0,e.eW)("https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging#KIP98ExactlyOnceDeliveryandTransactionalMessaging-AnExampleApplication"),(0,e.bF)(s)])])]),d])}]]),g=JSON.parse('{"path":"/code/%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/3.html","title":"Kafka - 3 客户端工作机制2","lang":"zh-CN","frontmatter":{"title":"Kafka - 3 客户端工作机制2","category":["code"],"tag":["中间件","Kafka"],"order":-0.6,"description":"客户端工作机制2 生产者消息缓存机制 目前已经分析了消费者组、消息发送和接受时的序列化和反序列化，以及具体消息发送是到哪个partition和consumer接受哪个partition的消息 接下来就是如何具体发送消息了 ​Kafka生产者为了避免高并发请求对服务端造成过大压力，每次发消息时并不是一条一条发往服务端，而是增加了一个高速缓存，将消息集中到...","head":[["meta",{"property":"og:url","content":"http://ekkosonya.cn/code/%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/3.html"}],["meta",{"property":"og:site_name","content":"EkkoSonya\'s Blog"}],["meta",{"property":"og:title","content":"Kafka - 3 客户端工作机制2"}],["meta",{"property":"og:description","content":"客户端工作机制2 生产者消息缓存机制 目前已经分析了消费者组、消息发送和接受时的序列化和反序列化，以及具体消息发送是到哪个partition和consumer接受哪个partition的消息 接下来就是如何具体发送消息了 ​Kafka生产者为了避免高并发请求对服务端造成过大压力，每次发消息时并不是一条一条发往服务端，而是增加了一个高速缓存，将消息集中到..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-20T14:16:53.000Z"}],["meta",{"property":"article:author","content":"EkkoSonya"}],["meta",{"property":"article:tag","content":"中间件"}],["meta",{"property":"article:tag","content":"Kafka"}],["meta",{"property":"article:modified_time","content":"2026-01-20T14:16:53.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka - 3 客户端工作机制2\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-20T14:16:53.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"EkkoSonya\\",\\"url\\":\\"http://ekkosonya.cn\\"}]}"]]},"headers":[{"level":2,"title":"客户端工作机制2","slug":"客户端工作机制2","link":"#客户端工作机制2","children":[{"level":3,"title":"生产者消息缓存机制","slug":"生产者消息缓存机制","link":"#生产者消息缓存机制","children":[{"level":4,"title":"RecordAccumulator","slug":"recordaccumulator","link":"#recordaccumulator","children":[{"level":5,"title":"主要参数 BUFFER_MEMORY_CONFIG + BATCH_SIZE_CONFIG","slug":"主要参数-buffer-memory-config-batch-size-config","link":"#主要参数-buffer-memory-config-batch-size-config","children":[]}]},{"level":4,"title":"Sender","slug":"sender","link":"#sender","children":[{"level":5,"title":"sender 什么时候去 Deque 拉取消息","slug":"sender-什么时候去-deque-拉取消息","link":"#sender-什么时候去-deque-拉取消息","children":[]},{"level":5,"title":"主要参数 LINGER_MS_CONFIG + MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION","slug":"主要参数-linger-ms-config-max-in-flight-requests-per-connection","link":"#主要参数-linger-ms-config-max-in-flight-requests-per-connection","children":[]}]}]},{"level":3,"title":"发送应答机制","slug":"发送应答机制","link":"#发送应答机制","children":[{"level":4,"title":"ack=1 or -1","slug":"ack-1-or-1","link":"#ack-1-or-1","children":[]},{"level":4,"title":"幂等性要求","slug":"幂等性要求","link":"#幂等性要求","children":[]}]},{"level":3,"title":"生产者消息幂等性","slug":"生产者消息幂等性","link":"#生产者消息幂等性","children":[{"level":4,"title":"幂等性问题","slug":"幂等性问题","link":"#幂等性问题","children":[{"level":5,"title":"分布式数据传递三个数据语义","slug":"分布式数据传递三个数据语义","link":"#分布式数据传递三个数据语义","children":[]}]},{"level":4,"title":"kafka 幂等性实现","slug":"kafka-幂等性实现","link":"#kafka-幂等性实现","children":[]},{"level":4,"title":"幂等性作用范围","slug":"幂等性作用范围","link":"#幂等性作用范围","children":[]},{"level":4,"title":"kafka 幂等性配置","slug":"kafka-幂等性配置","link":"#kafka-幂等性配置","children":[]}]},{"level":3,"title":"生产者数据压缩机制","slug":"生产者数据压缩机制","link":"#生产者数据压缩机制","children":[]},{"level":3,"title":"生产者消息事务","slug":"生产者消息事务","link":"#生产者消息事务","children":[{"level":4,"title":"事务API","slug":"事务api","link":"#事务api","children":[]},{"level":4,"title":"示例","slug":"示例","link":"#示例","children":[]},{"level":4,"title":"分析","slug":"分析","link":"#分析","children":[]}]},{"level":3,"title":"流程总结","slug":"流程总结","link":"#流程总结","children":[]}]}],"git":{"createdTime":1768918613000,"updatedTime":1768918613000,"contributors":[{"name":"EkkoSonya","email":"ekkosonya@163.com","commits":1}]},"readingTime":{"minutes":22.2,"words":6660},"filePathRelative":"code/中间件/Kafka/3.md","localizedDate":"2026年1月20日","excerpt":"<h2>客户端工作机制2</h2>\\n<h3>生产者消息缓存机制</h3>\\n<p>目前已经分析了消费者组、消息发送和接受时的序列化和反序列化，以及具体消息发送是到哪个partition和consumer接受哪个partition的消息</p>\\n<p>接下来就是如何具体发送消息了</p>\\n<p>​Kafka生产者为了避免高并发请求对服务端造成过大压力，每次发消息时并不是一条一条发往服务端，而是增加了一个高速缓存，将消息集中到缓存后，批量进行发送。这种缓存机制也是高并发处理时非常常用的一种机制</p>\\n<p>Kafka的消息缓存机制涉及到KafkaProducer中的两个关键组件： <code>accumulator</code> 和 <code>sender</code></p>","autoDesc":true}')}}]);